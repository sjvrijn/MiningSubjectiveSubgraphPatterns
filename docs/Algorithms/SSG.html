<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.8.3" />
<title>src.Algorithms.SSG API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js" integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>src.Algorithms.SSG</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">###################################################################################################################################################################
###################################################################################################################################################################
###################################################################################################################################################################
###################################################################################################################################################################
import os
import shutil
import sys

import pandas as pd
path = os.getcwd().split(&#39;MiningSubjectiveSubgraphPatterns&#39;)[0]+&#39;MiningSubjectiveSubgraphPatterns/&#39;
if path not in sys.path:
        sys.path.append(path)
import networkx as nx
import time
import argparse
import configparser
import ast
import ray

from src.BackgroundDistributions.MaxEntSimple import MaxEntSimpleU as PDMESU
from src.BackgroundDistributions.MaxEntSimple import MaxEntSimpleD as PDMESD
from src.BackgroundDistributions.UniDistSimple import UniDistSimple as PDUDS

from src.HillClimbers.HC_v4 import findBestPattern
###################################################################################################################################################################
def parseStr(x):
    &#34;&#34;&#34;
    function to parse a string

    Parameters
    ----------
    x : str
        input string

    Returns
    -------
    int or float or str
        parsed string
    &#34;&#34;&#34;
    try:
        return int(x)
    except ValueError:
        try:
            return float(x)
        except ValueError:
            return x
###################################################################################################################################################################
def readConfFile(fname):
    &#34;&#34;&#34;
    function to read the config file to run the experiment

    Parameters
    ----------
    fname : str
        input configuration file name

    Returns
    -------
    list, dict
        list of datasets and dictionary of required parameters

    Raises
    ------
    Exception
        if configuration file is not found
    &#34;&#34;&#34;
    config = configparser.ConfigParser()
    if os.path.exists(path+&#39;Confs/&#39;+fname):
        config.read(path+&#39;Confs/&#39;+fname)
        DS = ast.literal_eval(config[&#39;Datasets&#39;][&#39;DS&#39;])
        Params = dict()
        for i in config[&#39;SSG Params&#39;].items():
            Params[i[0]] = parseStr(i[1])
        return DS, Params
    else:
        raise Exception(&#39;Configuration file does not exists:&#39;, path+&#39;Confs/&#39;+fname)
    return
###################################################################################################################################################################
def getGraphAndBD(d, Params):
    &#34;&#34;&#34;
    function to read the graph and corresponding background distribution of the given type of prior belief

    Parameters
    ----------
    gname : str
        input filename of the graph
    Params : dict
        input parameters to run the experiment

    Returns
    -------
    networkx graph, PDClass, str
        Corresponding networkx graph, background distribution and graph type (undirected &#39;U&#39; or directed &#39;D&#39;) respectively

    Raises
    ------
    Exception
        more than one file is found in the input directory of gml or gpickle type
    Exception
        no input file type is found
    Exception
        if a specific type of prior belief given as input which is not implemented yet
    &#34;&#34;&#34;
    files = None
    if os.path.exists(path+&#39;Data/SSG/&#39;+d):
        files = os.listdir(path+&#39;Data/SSG/&#39;+d)
    Ffiles = dict()
    G = None
    PD = None
    print(files)
    print(Params)
    for f in files:
        if &#39;.gml&#39; in f:
            if &#39;.gml&#39; not in Ffiles:
                Ffiles[&#39;.gml&#39;] = f
            else:
                raise Exception(&#39;There shall be only one .GML file in the data directory&#39;)
        elif &#39;.gpickle&#39; in f:
            if &#39;.gpickle&#39; not in Ffiles:
                Ffiles[&#39;.gpickle&#39;] = f
            else:
                raise Exception(&#39;There shall be only one .gpickle file in the data directory&#39;)
    if &#39;.gml&#39; not in Ffiles and &#39;.gpickle&#39; not in Ffiles:
        raise Exception(&#39;No input graph file in the data directory. The directory shall contain a .gml or .gpickle file of input graph.&#39;)
    else:
        if &#39;.gpickle&#39; in Ffiles:
            G = nx.read_gpickle(path+&#39;Data/SSG/&#39;+d+&#39;/&#39;+Ffiles[&#39;.gpickle&#39;])
        else:
            G = nx.read_gml(path+&#39;Data/SSG/&#39;+d+&#39;/&#39;+Ffiles[&#39;.gml&#39;], destringizer=nx.readwrite.gml.literal_destringizer)

        if Params[&#39;priorbelief&#39;] is &#39;c&#39;:
            PD = PDUDS(G)
        elif Params[&#39;priorbelief&#39;] is &#39;i&#39;:
            if G.is_directed():
                PD = PDMESD(G)
            else:
                PD = PDMESU(G)
        else:
            raise Exception(&#39;Specified type of Belief is not yet implemented&#39;)
    return G, PD
###################################################################################################################################################################
def RunSSGUtil(d, Params):
    &#34;&#34;&#34;
    function to run SSG for one graph dataset

    Parameters
    ----------
    d : str
        dataset name
    Params : dict
        required parameters from config file to run the experiment

    Returns
    -------
    list, str
        list of found patterns and graph type (Undirected &#39;U&#39; or Directed &#39;D&#39;)
    &#34;&#34;&#34;
    G, PD = getGraphAndBD(d, Params)
    Patterns = list()
    gtype = &#39;D&#39; if G.is_directed() else &#39;U&#39;
    isSimple = False if G.is_multigraph() else True
    incEdges = True if Params[&#39;incedges&#39;] == 1 else False
    flag = True
    mxpats = sys.maxsize if Params[&#39;maxpatterns&#39;] == 0 else Params[&#39;maxpatterns&#39;]
    while flag:
        Pat = findBestPattern(G, PD, Params[&#39;q&#39;], Params[&#39;seedmode&#39;], Params[&#39;seedruns&#39;], 1, gtype, isSimple, incEdges)
        if len(Patterns) &lt; mxpats:
            if Pat is not None and Pat.NCount &gt; Params[&#39;minsize&#39;] and Pat.I &gt; Params[&#39;mininterest&#39;]:
                la = PD.updateDistribution(Pat.G, len(Patterns), &#39;save&#39;)
                Pat.setLambda(la)
                Patterns.append(Pat)
            else:
                print(&#39;Found all patterns with size and interestingness score greater than specified, finishing the task.....!!!!&#39;)
                flag = False
        if len(Patterns) &gt;= mxpats:
            print(&#39;Found maximum required patterns, finishing the task.....!!!!&#39;)
            flag = False
    return Patterns, gtype
###################################################################################################################################################################
def makeWritePath(ds):
    &#34;&#34;&#34;
    utility function to make proper path to write the results

    Parameters
    ----------
    ds : str
        current dataset name

    Returns
    -------
    str
        path of the folder in which the results to be written
    &#34;&#34;&#34;
    if not os.path.exists(path+&#39;Results/&#39;):
        os.mkdir(path+&#39;Results/&#39;)
    if not os.path.exists(path+&#39;Results/SSG/&#39;):
        os.mkdir(path+&#39;Results/SSG/&#39;)
    if not os.path.exists(path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;):
        os.mkdir(path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;)
    wpath = path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;+&#39;run_&#39;+str(int(time.time()))
    os.mkdir(wpath)
    return wpath+&#39;/&#39;
###################################################################################################################################################################
def writeToCSV(df, dfname, wpath):
    &#34;&#34;&#34;
    utility function of write a dataframe at the specified location and stored by the given name

    Parameters
    ----------
    df : pandas dataframe
        input dataframe to be written
    dfname : str
        name of the dataframe to be given in the final file
    wpath : str
        path to directory
    &#34;&#34;&#34;
    df.to_csv(wpath+dfname+&#39;.csv&#39;, index=False, sep=&#39;;&#39;)
    return
###################################################################################################################################################################
def writeResults(Patterns, df):
    &#34;&#34;&#34;
    utility function to write patterns in a pandas dataframe

    Parameters
    ----------
    Patterns : list
        list of patterns
    df : pandas dadaframe
        input dataframe

    Returns
    -------
    pandas dadaframe
        updated dataframe
    &#34;&#34;&#34;
    for pat in Patterns:
        df = df.append(pat.getDictForm(), ignore_index=True)
    return df
###################################################################################################################################################################
def RunSSG(fname):
    &#34;&#34;&#34;
    Function to run SSG

    Parameters
    ----------
    fname : str
        filename of the configuration file found in &#34;Confs&#34; directory
    &#34;&#34;&#34;
    if not ray.is_initialized():
        ray.init()
    DS, Params = readConfFile(fname)
    for d in DS:
        wpath = makeWritePath(d)
        log = open(wpath+&#39;run.logs&#39;, &#39;a&#39;)
        sys.stdout = log
        stime = time.time()
        Patterns, gtype = RunSSGUtil(d, Params)
        ftime = time.time()
        p_cols = None
        if gtype is &#39;U&#39;:
            p_cols = [&#39;state_info&#39;, &#39;pat_type&#39;, &#39;prev_order&#39;, &#39;cur_order&#39;, &#39;NCount&#39;, &#39;ECount&#39;, &#39;Density&#39;,\
                &#39;I&#39;, &#39;DL&#39;, &#39;IC_ssg&#39;, &#39;AD&#39;, &#39;IC_dssg&#39;, &#39;IC_dsimp&#39;, &#39;la&#39;, &#39;sumPOS&#39;, &#39;expectedEdges&#39;, &#39;NL&#39;,\
                &#39;kws&#39;, &#39;nw&#39;, &#39;minPOS&#39;]
        else:
            p_cols = [&#39;state_info&#39;, &#39;pat_type&#39;, &#39;prev_order&#39;, &#39;cur_order&#39;, &#39;InNCount&#39;, &#39;OutNCount&#39;, &#39;ECount&#39;, &#39;Density&#39;,\
                &#39;I&#39;, &#39;DL&#39;, &#39;IC_ssg&#39;, &#39;AD&#39;, &#39;IC_dssg&#39;, &#39;IC_dsimp&#39;, &#39;la&#39;, &#39;sumPOS&#39;, &#39;expectedEdges&#39;, &#39;inNL&#39;,\
                &#39;outNL&#39;, &#39;kws&#39;, &#39;nw&#39;, &#39;minPOS&#39;]
        df_patterns = pd.DataFrame(columns = p_cols)
        df_patterns = writeResults(Patterns, df_patterns)
        writeToCSV(df_patterns, &#39;patterns&#39;, wpath)
        shutil.copy(path+&#39;Confs/&#39;+fname, wpath+&#39;conf.txt&#39;)
        print(&#39;\n\n\nTotal Time Taken: {:.4f} seconds&#39;.format(ftime-stime))
        log.close()
    return
###################################################################################################################################################################
if __name__ == &#34;__main__&#34;:
    parser = argparse.ArgumentParser(description=&#39;Running SSG&#39;)
    parser.add_argument(dest =&#39;filename&#39;, metavar =&#39;filename&#39;, type=str, help=&#39;configuration filename to run SSG.py&#39;)
    args = parser.parse_args()
    RunSSG(args.filename)
###################################################################################################################################################################
###################################################################################################################################################################
###################################################################################################################################################################
###################################################################################################################################################################</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="src.Algorithms.SSG.RunSSG"><code class="name flex">
<span>def <span class="ident">RunSSG</span></span>(<span>fname)</span>
</code></dt>
<dd>
<div class="desc"><p>Function to run SSG</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fname</code></strong> :&ensp;<code>str</code></dt>
<dd>filename of the configuration file found in "Confs" directory</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def RunSSG(fname):
    &#34;&#34;&#34;
    Function to run SSG

    Parameters
    ----------
    fname : str
        filename of the configuration file found in &#34;Confs&#34; directory
    &#34;&#34;&#34;
    if not ray.is_initialized():
        ray.init()
    DS, Params = readConfFile(fname)
    for d in DS:
        wpath = makeWritePath(d)
        log = open(wpath+&#39;run.logs&#39;, &#39;a&#39;)
        sys.stdout = log
        stime = time.time()
        Patterns, gtype = RunSSGUtil(d, Params)
        ftime = time.time()
        p_cols = None
        if gtype is &#39;U&#39;:
            p_cols = [&#39;state_info&#39;, &#39;pat_type&#39;, &#39;prev_order&#39;, &#39;cur_order&#39;, &#39;NCount&#39;, &#39;ECount&#39;, &#39;Density&#39;,\
                &#39;I&#39;, &#39;DL&#39;, &#39;IC_ssg&#39;, &#39;AD&#39;, &#39;IC_dssg&#39;, &#39;IC_dsimp&#39;, &#39;la&#39;, &#39;sumPOS&#39;, &#39;expectedEdges&#39;, &#39;NL&#39;,\
                &#39;kws&#39;, &#39;nw&#39;, &#39;minPOS&#39;]
        else:
            p_cols = [&#39;state_info&#39;, &#39;pat_type&#39;, &#39;prev_order&#39;, &#39;cur_order&#39;, &#39;InNCount&#39;, &#39;OutNCount&#39;, &#39;ECount&#39;, &#39;Density&#39;,\
                &#39;I&#39;, &#39;DL&#39;, &#39;IC_ssg&#39;, &#39;AD&#39;, &#39;IC_dssg&#39;, &#39;IC_dsimp&#39;, &#39;la&#39;, &#39;sumPOS&#39;, &#39;expectedEdges&#39;, &#39;inNL&#39;,\
                &#39;outNL&#39;, &#39;kws&#39;, &#39;nw&#39;, &#39;minPOS&#39;]
        df_patterns = pd.DataFrame(columns = p_cols)
        df_patterns = writeResults(Patterns, df_patterns)
        writeToCSV(df_patterns, &#39;patterns&#39;, wpath)
        shutil.copy(path+&#39;Confs/&#39;+fname, wpath+&#39;conf.txt&#39;)
        print(&#39;\n\n\nTotal Time Taken: {:.4f} seconds&#39;.format(ftime-stime))
        log.close()
    return</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.RunSSGUtil"><code class="name flex">
<span>def <span class="ident">RunSSGUtil</span></span>(<span>d, Params)</span>
</code></dt>
<dd>
<div class="desc"><p>function to run SSG for one graph dataset</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>d</code></strong> :&ensp;<code>str</code></dt>
<dd>dataset name</dd>
<dt><strong><code>Params</code></strong> :&ensp;<code>dict</code></dt>
<dd>required parameters from config file to run the experiment</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list, str</code></dt>
<dd>list of found patterns and graph type (Undirected 'U' or Directed 'D')</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def RunSSGUtil(d, Params):
    &#34;&#34;&#34;
    function to run SSG for one graph dataset

    Parameters
    ----------
    d : str
        dataset name
    Params : dict
        required parameters from config file to run the experiment

    Returns
    -------
    list, str
        list of found patterns and graph type (Undirected &#39;U&#39; or Directed &#39;D&#39;)
    &#34;&#34;&#34;
    G, PD = getGraphAndBD(d, Params)
    Patterns = list()
    gtype = &#39;D&#39; if G.is_directed() else &#39;U&#39;
    isSimple = False if G.is_multigraph() else True
    incEdges = True if Params[&#39;incedges&#39;] == 1 else False
    flag = True
    mxpats = sys.maxsize if Params[&#39;maxpatterns&#39;] == 0 else Params[&#39;maxpatterns&#39;]
    while flag:
        Pat = findBestPattern(G, PD, Params[&#39;q&#39;], Params[&#39;seedmode&#39;], Params[&#39;seedruns&#39;], 1, gtype, isSimple, incEdges)
        if len(Patterns) &lt; mxpats:
            if Pat is not None and Pat.NCount &gt; Params[&#39;minsize&#39;] and Pat.I &gt; Params[&#39;mininterest&#39;]:
                la = PD.updateDistribution(Pat.G, len(Patterns), &#39;save&#39;)
                Pat.setLambda(la)
                Patterns.append(Pat)
            else:
                print(&#39;Found all patterns with size and interestingness score greater than specified, finishing the task.....!!!!&#39;)
                flag = False
        if len(Patterns) &gt;= mxpats:
            print(&#39;Found maximum required patterns, finishing the task.....!!!!&#39;)
            flag = False
    return Patterns, gtype</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.getGraphAndBD"><code class="name flex">
<span>def <span class="ident">getGraphAndBD</span></span>(<span>d, Params)</span>
</code></dt>
<dd>
<div class="desc"><p>function to read the graph and corresponding background distribution of the given type of prior belief</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>gname</code></strong> :&ensp;<code>str</code></dt>
<dd>input filename of the graph</dd>
<dt><strong><code>Params</code></strong> :&ensp;<code>dict</code></dt>
<dd>input parameters to run the experiment</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>networkx graph, PDClass, str</code></dt>
<dd>Corresponding networkx graph, background distribution and graph type (undirected 'U' or directed 'D') respectively</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>more than one file is found in the input directory of gml or gpickle type</dd>
<dt><code>Exception</code></dt>
<dd>no input file type is found</dd>
<dt><code>Exception</code></dt>
<dd>if a specific type of prior belief given as input which is not implemented yet</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def getGraphAndBD(d, Params):
    &#34;&#34;&#34;
    function to read the graph and corresponding background distribution of the given type of prior belief

    Parameters
    ----------
    gname : str
        input filename of the graph
    Params : dict
        input parameters to run the experiment

    Returns
    -------
    networkx graph, PDClass, str
        Corresponding networkx graph, background distribution and graph type (undirected &#39;U&#39; or directed &#39;D&#39;) respectively

    Raises
    ------
    Exception
        more than one file is found in the input directory of gml or gpickle type
    Exception
        no input file type is found
    Exception
        if a specific type of prior belief given as input which is not implemented yet
    &#34;&#34;&#34;
    files = None
    if os.path.exists(path+&#39;Data/SSG/&#39;+d):
        files = os.listdir(path+&#39;Data/SSG/&#39;+d)
    Ffiles = dict()
    G = None
    PD = None
    print(files)
    print(Params)
    for f in files:
        if &#39;.gml&#39; in f:
            if &#39;.gml&#39; not in Ffiles:
                Ffiles[&#39;.gml&#39;] = f
            else:
                raise Exception(&#39;There shall be only one .GML file in the data directory&#39;)
        elif &#39;.gpickle&#39; in f:
            if &#39;.gpickle&#39; not in Ffiles:
                Ffiles[&#39;.gpickle&#39;] = f
            else:
                raise Exception(&#39;There shall be only one .gpickle file in the data directory&#39;)
    if &#39;.gml&#39; not in Ffiles and &#39;.gpickle&#39; not in Ffiles:
        raise Exception(&#39;No input graph file in the data directory. The directory shall contain a .gml or .gpickle file of input graph.&#39;)
    else:
        if &#39;.gpickle&#39; in Ffiles:
            G = nx.read_gpickle(path+&#39;Data/SSG/&#39;+d+&#39;/&#39;+Ffiles[&#39;.gpickle&#39;])
        else:
            G = nx.read_gml(path+&#39;Data/SSG/&#39;+d+&#39;/&#39;+Ffiles[&#39;.gml&#39;], destringizer=nx.readwrite.gml.literal_destringizer)

        if Params[&#39;priorbelief&#39;] is &#39;c&#39;:
            PD = PDUDS(G)
        elif Params[&#39;priorbelief&#39;] is &#39;i&#39;:
            if G.is_directed():
                PD = PDMESD(G)
            else:
                PD = PDMESU(G)
        else:
            raise Exception(&#39;Specified type of Belief is not yet implemented&#39;)
    return G, PD</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.makeWritePath"><code class="name flex">
<span>def <span class="ident">makeWritePath</span></span>(<span>ds)</span>
</code></dt>
<dd>
<div class="desc"><p>utility function to make proper path to write the results</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>ds</code></strong> :&ensp;<code>str</code></dt>
<dd>current dataset name</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>str</code></dt>
<dd>path of the folder in which the results to be written</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def makeWritePath(ds):
    &#34;&#34;&#34;
    utility function to make proper path to write the results

    Parameters
    ----------
    ds : str
        current dataset name

    Returns
    -------
    str
        path of the folder in which the results to be written
    &#34;&#34;&#34;
    if not os.path.exists(path+&#39;Results/&#39;):
        os.mkdir(path+&#39;Results/&#39;)
    if not os.path.exists(path+&#39;Results/SSG/&#39;):
        os.mkdir(path+&#39;Results/SSG/&#39;)
    if not os.path.exists(path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;):
        os.mkdir(path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;)
    wpath = path+&#39;Results/SSG/&#39;+ds+&#39;/&#39;+&#39;run_&#39;+str(int(time.time()))
    os.mkdir(wpath)
    return wpath+&#39;/&#39;</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.parseStr"><code class="name flex">
<span>def <span class="ident">parseStr</span></span>(<span>x)</span>
</code></dt>
<dd>
<div class="desc"><p>function to parse a string</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>x</code></strong> :&ensp;<code>str</code></dt>
<dd>input string</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>int</code> or <code>float</code> or <code>str</code></dt>
<dd>parsed string</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def parseStr(x):
    &#34;&#34;&#34;
    function to parse a string

    Parameters
    ----------
    x : str
        input string

    Returns
    -------
    int or float or str
        parsed string
    &#34;&#34;&#34;
    try:
        return int(x)
    except ValueError:
        try:
            return float(x)
        except ValueError:
            return x</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.readConfFile"><code class="name flex">
<span>def <span class="ident">readConfFile</span></span>(<span>fname)</span>
</code></dt>
<dd>
<div class="desc"><p>function to read the config file to run the experiment</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>fname</code></strong> :&ensp;<code>str</code></dt>
<dd>input configuration file name</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>list, dict</code></dt>
<dd>list of datasets and dictionary of required parameters</dd>
</dl>
<h2 id="raises">Raises</h2>
<dl>
<dt><code>Exception</code></dt>
<dd>if configuration file is not found</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def readConfFile(fname):
    &#34;&#34;&#34;
    function to read the config file to run the experiment

    Parameters
    ----------
    fname : str
        input configuration file name

    Returns
    -------
    list, dict
        list of datasets and dictionary of required parameters

    Raises
    ------
    Exception
        if configuration file is not found
    &#34;&#34;&#34;
    config = configparser.ConfigParser()
    if os.path.exists(path+&#39;Confs/&#39;+fname):
        config.read(path+&#39;Confs/&#39;+fname)
        DS = ast.literal_eval(config[&#39;Datasets&#39;][&#39;DS&#39;])
        Params = dict()
        for i in config[&#39;SSG Params&#39;].items():
            Params[i[0]] = parseStr(i[1])
        return DS, Params
    else:
        raise Exception(&#39;Configuration file does not exists:&#39;, path+&#39;Confs/&#39;+fname)
    return</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.writeResults"><code class="name flex">
<span>def <span class="ident">writeResults</span></span>(<span>Patterns, df)</span>
</code></dt>
<dd>
<div class="desc"><p>utility function to write patterns in a pandas dataframe</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>Patterns</code></strong> :&ensp;<code>list</code></dt>
<dd>list of patterns</dd>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas dadaframe</code></dt>
<dd>input dataframe</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas dadaframe</code></dt>
<dd>updated dataframe</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def writeResults(Patterns, df):
    &#34;&#34;&#34;
    utility function to write patterns in a pandas dataframe

    Parameters
    ----------
    Patterns : list
        list of patterns
    df : pandas dadaframe
        input dataframe

    Returns
    -------
    pandas dadaframe
        updated dataframe
    &#34;&#34;&#34;
    for pat in Patterns:
        df = df.append(pat.getDictForm(), ignore_index=True)
    return df</code></pre>
</details>
</dd>
<dt id="src.Algorithms.SSG.writeToCSV"><code class="name flex">
<span>def <span class="ident">writeToCSV</span></span>(<span>df, dfname, wpath)</span>
</code></dt>
<dd>
<div class="desc"><p>utility function of write a dataframe at the specified location and stored by the given name</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>df</code></strong> :&ensp;<code>pandas dataframe</code></dt>
<dd>input dataframe to be written</dd>
<dt><strong><code>dfname</code></strong> :&ensp;<code>str</code></dt>
<dd>name of the dataframe to be given in the final file</dd>
<dt><strong><code>wpath</code></strong> :&ensp;<code>str</code></dt>
<dd>path to directory</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def writeToCSV(df, dfname, wpath):
    &#34;&#34;&#34;
    utility function of write a dataframe at the specified location and stored by the given name

    Parameters
    ----------
    df : pandas dataframe
        input dataframe to be written
    dfname : str
        name of the dataframe to be given in the final file
    wpath : str
        path to directory
    &#34;&#34;&#34;
    df.to_csv(wpath+dfname+&#39;.csv&#39;, index=False, sep=&#39;;&#39;)
    return</code></pre>
</details>
</dd>
</dl>
</section>
<section>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="src.Algorithms" href="index.html">src.Algorithms</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="two-column">
<li><code><a title="src.Algorithms.SSG.RunSSG" href="#src.Algorithms.SSG.RunSSG">RunSSG</a></code></li>
<li><code><a title="src.Algorithms.SSG.RunSSGUtil" href="#src.Algorithms.SSG.RunSSGUtil">RunSSGUtil</a></code></li>
<li><code><a title="src.Algorithms.SSG.getGraphAndBD" href="#src.Algorithms.SSG.getGraphAndBD">getGraphAndBD</a></code></li>
<li><code><a title="src.Algorithms.SSG.makeWritePath" href="#src.Algorithms.SSG.makeWritePath">makeWritePath</a></code></li>
<li><code><a title="src.Algorithms.SSG.parseStr" href="#src.Algorithms.SSG.parseStr">parseStr</a></code></li>
<li><code><a title="src.Algorithms.SSG.readConfFile" href="#src.Algorithms.SSG.readConfFile">readConfFile</a></code></li>
<li><code><a title="src.Algorithms.SSG.writeResults" href="#src.Algorithms.SSG.writeResults">writeResults</a></code></li>
<li><code><a title="src.Algorithms.SSG.writeToCSV" href="#src.Algorithms.SSG.writeToCSV">writeToCSV</a></code></li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.8.3</a>.</p>
</footer>
</body>
</html>